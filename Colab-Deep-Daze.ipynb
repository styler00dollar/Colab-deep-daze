{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von Deep Daze",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMOyHqy8wt1H"
      },
      "source": [
        "# Colab-deep-daze\r\n",
        "Original repo: [lucidrains/deep-daze](https://github.com/lucidrains/deep-daze)\r\n",
        "\r\n",
        "My fork: [styler00dollar/Colab-deep-daze](https://github.com/styler00dollar/Colab-deep-daze)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP3u8c3IpMld"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55YJsbFV10i8",
        "cellView": "form"
      },
      "source": [
        "#@title Install\n",
        "import subprocess\n",
        "\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\"\n",
        "\n",
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n",
        "!pip install deep-daze"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cskITQNpwEW6"
      },
      "source": [
        "# Using Google Drive and disabling heavy printing to avoid output size limit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCBTrL3XqXf-",
        "cellView": "form"
      },
      "source": [
        "#@title Mount Google Drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "print('Google Drive connected.')\r\n",
        "!mkdir '/content/drive/MyDrive/DeepDaze/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy2SvlEMxHVH"
      },
      "source": [
        "Current default is ```!mkdir '/content/drive/MyDrive/DeepDaze/'```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IPQ_rdA2Sa7",
        "cellView": "form"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from IPython.display import Image, display\n",
        "import shutil\n",
        "\n",
        "from deep_daze import Imagine\n",
        "\n",
        "save_path = '/content/drive/MyDrive/DeepDaze/' #@param {type:\"string\"}\n",
        "TEXT = 'happy anime character' #@param {type:\"string\"}\n",
        "TEXT_PATH = TEXT.replace(\" \", \"_\")\n",
        "NUM_LAYERS = 32 #@param {type:\"number\"}\n",
        "\n",
        "model = Imagine(\n",
        "    text = TEXT,\n",
        "    num_layers = NUM_LAYERS,\n",
        "    save_every = 50 #@param {type:\"number\"}\n",
        ")\n",
        "\n",
        "# without heavy printing and saving images to drive\n",
        "for epoch in range(20):\n",
        "    for i in range(1000):\n",
        "        model.train_step(epoch, i)\n",
        "\n",
        "        if i % model.save_every != 0:\n",
        "            continue\n",
        "\n",
        "        file_end = str(\"_\"+str({epoch})+\"_\"+str({i})+\".png\")\n",
        "        source = f'{TEXT_PATH}.png'\n",
        "        destination = f'{save_path}{TEXT_PATH}{file_end}'\n",
        "        print(source, destination)\n",
        "        shutil.move(source, destination)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R96Ci-EZwQ-_"
      },
      "source": [
        "# Original with trange"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU7XY-2PwTAD"
      },
      "source": [
        "Warning: In this current state you will get ```Buffered data was truncated after reaching the output size limit.``` after a while and thus dont see further progress. Combined with Colabs terminating behaviour and risking to loose the output with missing printing, this is not really a good idea to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFVG3rGVp-_S",
        "cellView": "form"
      },
      "source": [
        "from tqdm import trange\r\n",
        "from IPython.display import Image, display\r\n",
        "\r\n",
        "from deep_daze import Imagine\r\n",
        "\r\n",
        "TEXT = 'an apple next to a fireplace' #@param {type:\"string\"}\r\n",
        "NUM_LAYERS = 32 #@param {type:\"number\"}\r\n",
        "\r\n",
        "model = Imagine(\r\n",
        "    text = TEXT,\r\n",
        "    num_layers = NUM_LAYERS,\r\n",
        "    save_every = 50\r\n",
        ")\r\n",
        "\r\n",
        "for epoch in trange(20, desc = 'epochs'):\r\n",
        "    for i in trange(1000, desc = 'iteration'):\r\n",
        "        model.train_step(epoch, i)\r\n",
        "\r\n",
        "        if i % model.save_every != 0:\r\n",
        "            continue\r\n",
        "\r\n",
        "        image = Image(f'./{TEXT}.png')\r\n",
        "        display(image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}